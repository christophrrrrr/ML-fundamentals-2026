{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "74d42372",
   "metadata": {},
   "source": [
    "\n",
    "# Individual Assignment I: Machine Learning Foundation\n",
    "**Data Preparation**\n",
    "\n",
    "GitHub Repository: [https://github.com/christophrrrrr/Machine-Learning-Assignment-1.git](https://github.com/christophrrrrr/Machine-Learning-Assignment-1.git)\n",
    "\n",
    "This notebook executes data preparation and feature engineering tasks for the UCI Bank Marketing Dataset (`bank-additional.csv`), in strict adherence to data leakage prevention principles.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18cb43c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, ConfusionMatrixDisplay\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be366ac3",
   "metadata": {},
   "source": [
    "\n",
    "## 1. Identifying the Prediction Target\n",
    "\n",
    "*Lecture material: Lecture 1 (Problem Formulation), Lecture 2 (Data Inspection).*\n",
    "\n",
    "**Target Selection:**\n",
    "The target variable is `y`. Upon manual inspection of the dataset description and features, `y` records `\"yes\"` or `\"no\"` indicating whether the client subscribed to a term deposit. This aligns perfectly with the stated objective of the direct marketing campaigns.\n",
    "\n",
    "**Invalid Alternatives:**\n",
    "Two other variables might superficially appear to be valid targets but must not be used:\n",
    "1. `duration`: This represents the call duration in seconds. While highly correlated with `y` (since successful sales usually take longer to close), it is strictly an outcome of the call. At prediction time (before or during the start of the call), this information is strictly unavailable. Predicting `duration` does not answer the business goal of identifying *who* will subscribe. Including it would result in catastrophic data leakage.\n",
    "2. `poutcome`: This records the outcome of the *previous* marketing campaign. While useful as a predictive feature, it addresses a past event, whereas the current campaign's goal is measuring the present response (`y`).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5036bc21",
   "metadata": {},
   "source": [
    "\n",
    "## 2. Data Loading and Exploration\n",
    "\n",
    "*Lecture material: Lecture 1 (Problem Formulation), Lecture 2 (Data Inspection and EDA).*\n",
    "\n",
    "We load the dataset `bank-additional.csv`. Note that UCI bank datasets commonly use the semicolon `;` separator.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e098f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load dataset\n",
    "import os\n",
    "\n",
    "filepath = 'data/bank-additional.csv'\n",
    "github_url = 'https://raw.githubusercontent.com/christophrrrrr/ML-fundamentals-2026/main/data/bank-additional.csv'\n",
    "\n",
    "# Make it completely compatible with Google Colab or isolated executions\n",
    "if os.path.exists(filepath):\n",
    "    df = pd.read_csv(filepath, sep=';')\n",
    "else:\n",
    "    print(f\"Local instance of dataset not found. Downloading directly from GitHub repository...\")\n",
    "    df = pd.read_csv(github_url, sep=';')\n",
    "\n",
    "# Basic structure\n",
    "print(f\"Number of observations: {df.shape[0]}\")\n",
    "print(f\"Number of features: {df.shape[1]}\")\n",
    "\n",
    "print(\"\\n--- Data Types ---\")\n",
    "print(df.dtypes)\n",
    "\n",
    "print(\"\\n--- Summary Statistics ---\")\n",
    "display(df.describe())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c79c06df",
   "metadata": {},
   "source": [
    "\n",
    "**Variable Identification:**\n",
    "- **Numerical:** `age`, `duration`, `campaign`, `pdays`, `previous`, `emp.var.rate`, `cons.price.idx`, `cons.conf.idx`, `euribor3m`, `nr.employed`\n",
    "- **Categorical:** `job`, `marital`, `education`, `default`, `housing`, `loan`, `contact`, `month`, `day_of_week`, `poutcome`, `y`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "588498b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Target Distribution\n",
    "y_counts = df['y'].value_counts()\n",
    "y_pct = df['y'].value_counts(normalize=True)\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(16, 4))\n",
    "df['y'].value_counts().plot(kind='bar', color=['#1f77b4', '#ff7f0e'], ax=axes[0])\n",
    "axes[0].set_title('Target Variable (y) Distribution')\n",
    "axes[0].set_ylabel('Count')\n",
    "\n",
    "# Numerical Plot\n",
    "df['age'].plot(kind='hist', bins=20, color='skyblue', edgecolor='black', ax=axes[1])\n",
    "axes[1].set_title('Age Distribution')\n",
    "\n",
    "# Categorical Plot\n",
    "df['job'].value_counts().plot(kind='bar', color='lightgreen', edgecolor='black', ax=axes[2])\n",
    "axes[2].set_title('Job Category Distribution')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Target variable counts:\")\n",
    "print(y_counts)\n",
    "print(\"\\nTarget variable percentages:\")\n",
    "print(y_pct)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b703557a",
   "metadata": {},
   "source": [
    "\n",
    "**Observations:**\n",
    "- **Class Imbalance:** Only ~10.9% of clients subscribed (`yes`), meaning early handling for class imbalance will be required to prevent the model from trivializing predictions to the majority class.\n",
    "- **Special Consideration Variable (`duration`):** As noted, `duration` represents the length of the call. Because this is unknown *before* the call starts—which is the prediction moment—it causes severe data leakage. We must rigorously exclude it before modeling.\n",
    "- **Implicit Missing Values:** Several categorical variables (like `job` or `education`) utilize the string `\"unknown\"` as an implicit missing value. The numerical variable `pdays` uses `999` to declare \"never contacted before\".\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e580dcf",
   "metadata": {},
   "source": [
    "\n",
    "## 3. Task Ordering\n",
    "\n",
    "*Lecture material: Lecture 2 (Data Splitting and Leakage), Lecture 5 (Preprocessing), Lecture 9 (ML Pipeline).*\n",
    "\n",
    "To strictly prevent data leakage and abide by ML Pipeline discipline, I execute the data preparation tasks in the following sequence:\n",
    "\n",
    "1. **Identifying Target & Data Loading** (Completed above): Understand the objective before transformations.\n",
    "2. **Managing Missing Values (Identification & Structural Cleaning):** Convert sentinels like `\"unknown\"` or `999` into structural `NaN` values. *Why here?* Because finding string literals does not rely on global sample statistics (like mean/mode), so no leakage occurs.\n",
    "3. **Data Splitting:** Divide into Train, Validation, and Test sets. *Why here?* Splitting MUST happen before any statistical operations. If it happens later, information from the test set would subtly influence the training parameters (Data Leakage).\n",
    "4. **Managing Missing Values (Statistical Imputation):** Compute median/mode strictly on the Train set and apply to Validation/Test.\n",
    "5. **Encoding Categorical Variables:** Fit OneHotEncoders on the Train set to define the dummy columns, avoiding learning about new categories from the Test set.\n",
    "6. **Feature Scaling:** Fit `StandardScaler` on the Train set to compute mean/variance, then apply to Validation/Test.\n",
    "7. **Feature Selection:** Analyze correlations and variance on the Train set only.\n",
    "8. **Addressing Class Imbalance:** Apply technique (like class weights or SMOTE) strictly on the encoded, scaled Train set.\n",
    "9. **Modeling:** Train Logistic Regression on Train, evaluate on Validation.\n",
    "\n",
    "**Incorrect Ordering Example:** \n",
    "If we performed **Feature Scaling** before **Data Splitting**, we would calculate the mean and standard deviation across the *entire* dataset. The standardized test values would inherently contain information about the central tendency of the training set. This is a classic form of data leakage, artificially inflating the test evaluation metrics because the test data \"peeked\" into the global distribution.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d91ec9e",
   "metadata": {},
   "source": [
    "\n",
    "## 4. Managing Missing Values (Part 1: Identification & Sentinel Cleaning)\n",
    "\n",
    "*Lecture material: Lecture 2 (Data Inspection), Lecture 5 (Preprocessing and Pipeline Discipline).*\n",
    "\n",
    "**Identification:**\n",
    "- Explicit missing values (`NaN`) are largely absent in this CSV.\n",
    "- Implicit missing values are abundant. Words like `\"unknown\"` map strictly to missing information. \n",
    "- In numerical columns, `pdays=999` acts as a sentinel for \"client was not previously contacted\".\n",
    "\n",
    "We must convert these implicit symbols into standard structural missingness (`NaN`) before splitting, alongside creating feature flags.\n",
    "\n",
    "*Note on Leakage:* Because we are just structurally replacing `\"unknown\" -> NaN` and extracting `pdays != 999`, we are not calculating statistics. Therefore, this is purely \"data cleaning\" and is safe to execute before Data Splitting.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "258b9652",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Drop 'duration' immediately to avoid leakage\n",
    "if 'duration' in df.columns:\n",
    "    df = df.drop(columns=['duration'])\n",
    "\n",
    "# 1. Handle Categorical 'unknown'\n",
    "cat_cols = df.select_dtypes(include=['object']).columns\n",
    "for col in cat_cols:\n",
    "    df[col] = df[col].replace('unknown', np.nan)\n",
    "\n",
    "# 2. Handle 'pdays' Sentinel\n",
    "# Create a logical flag for previous contact\n",
    "df['prev_contacted'] = (df['pdays'] != 999).astype(int)\n",
    "# Clean the magnitude (so 999 doesn't distort linear models)\n",
    "df['pdays_clean'] = df['pdays'].replace(999, np.nan)\n",
    "df = df.drop(columns=['pdays'])\n",
    "\n",
    "missing_summary = df.isna().sum()\n",
    "print(\"Missing (NaN) counts after structured cleaning:\")\n",
    "print(missing_summary[missing_summary > 0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b072bef",
   "metadata": {},
   "source": [
    "\n",
    "## 5. Data Splitting\n",
    "\n",
    "*Lecture material: Lecture 2 (Data Splitting and Leakage), Lecture 9 (ML Pipeline).*\n",
    "\n",
    "I separate the independent features `X` and the target `y`, and perform a stratified split.\n",
    "\n",
    "**Proportions:** \n",
    "- Training: 70% (Used strictly to learn parameters for imputation, scaling, encoding, and modeling).\n",
    "- Validation: 15% (Used to evaluate model health during iterations and tune hyperparameters).\n",
    "- Test: 15% (Strictly held-out vault for final generalization reporting; untouched here).\n",
    "\n",
    "**Stratification:** We use `stratify=y` because the target is highly imbalanced (~11% positives). A random split could accidentally yield a training set with very few positive examples, leading to instability.\n",
    "\n",
    "**Leakage Prevention:** By executing this split NOW, I guarantee that upcoming steps (Scaling, Imputation, Encoding) can only `fit()` on mathematical properties isolated inside `X_train`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b25bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X = df.drop(columns=['y'])\n",
    "y = df['y']\n",
    "\n",
    "# First split: Train (70%), Temp (30%)\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "    X, y, test_size=0.30, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "# Second split: Temp -> Validation (50% of 30% = 15%) and Test (15%)\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.50, stratify=y_temp, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "print(f\"X_val shape: {X_val.shape}\")\n",
    "print(f\"X_test shape: {X_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03186710",
   "metadata": {},
   "source": [
    "\n",
    "## 6. Managing Missing Values (Part 2: Imputation)\n",
    "\n",
    "Now that data is split safely, we establish the statistical modeling logic inside `scikit-learn` Pipelines.\n",
    "\n",
    "- **Numerical Imputation:** For `pdays_clean`, we impute with the constant `-1` (or median). Because it is a duration, median is robust.\n",
    "- **Categorical Imputation:** We replace categorical `NaN` with the explicit string `\"missing\"`. This honors the *informative nature* of the missingness (perhaps clients who refuse to disclose `job` are empirically less likely to subscribe).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95084578",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "num_cols = X_train.select_dtypes(include=[np.number]).columns.tolist()\n",
    "cat_cols = X_train.select_dtypes(exclude=[np.number]).columns.tolist()\n",
    "\n",
    "# Define Imputers\n",
    "num_imputer = SimpleImputer(strategy='median')\n",
    "cat_imputer = SimpleImputer(strategy='constant', fill_value='missing')\n",
    "\n",
    "# We hold off assembling the full ColumnTransformer until we define Scaling/Encoding.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "390ceefc",
   "metadata": {},
   "source": [
    "\n",
    "## 7. Encoding Categorical Variables\n",
    "\n",
    "*Lecture material: Lecture 4 (Categorical Encoding), Lecture 6 (Linear Models).*\n",
    "\n",
    "**Classification:**\n",
    "- **Nominal Variables** (e.g., `job`, `marital`, `contact`, `month`): No intrinsic mathematical order.\n",
    "- **Ordinal Variables** (e.g., `education`): Intrinsic order (`basic.4y` < `high.school` < `university.degree`). \n",
    "\n",
    "**Strategy:**\n",
    "While `education` is logically ordinal, the step-sizes between levels are unknown. A linear model assumes uniform mathematical steps in an OrdinalEncoded variable (e.g., 1 -> 2 has the exact same impact as 2 -> 3). To avoid imposing this rigid, artificial structure, I apply **One-Hot Encoding** to *all* categorical variables.\n",
    "\n",
    "*Impact on Dimensionality:* Expands from ~10 categorical columns to dozens of sparse binary features.\n",
    "*Impact on Interpretability:* The Logistic Regression will yield a discrete coefficient for *each* category (e.g., `job_retired`), making it highly interpretable.\n",
    "*Impact on Decision Boundaries:* Allows the linear model to form piecewise, non-linear logic through intercepts added for specific subgroups.\n",
    "\n",
    "**Data Leakage Check:** I enforce `handle_unknown='ignore'`. If the Validation set contains a category unseen in Train, it ignores it rather than crashing, preventing leakage.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "babe055e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "onehot = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
    "\n",
    "cat_pipe = Pipeline([\n",
    "    ('imputer', cat_imputer),\n",
    "    ('onehot', onehot)\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c2546a1",
   "metadata": {},
   "source": [
    "\n",
    "## 8. Feature Scaling\n",
    "\n",
    "*Lecture material: Lecture 5 (Feature Scaling), Lecture 6 (Logistic Regression).*\n",
    "\n",
    "**Strategy:**\n",
    "I apply **Standardization** (`StandardScaler`) to all numerical features.\n",
    "\n",
    "**Justification for Logistic Regression:**\n",
    "- *Gradient Optimization:* Logistic regression loss surfaces (binary cross-entropy) converge much faster using gradient descent/lbfgs when features are centered and share similar variances.\n",
    "- *Regularization:* `scikit-learn`'s LogisticRegression includes L2 regularization by default. L2 drastically punishes variables with large magnitudes. If an unscaled feature spans $[0, 5000]$ (`nr.employed`), it will artificially shrink its coefficient. Scaling puts all features on the same numerical ground, normalizing the L2 penalty evenly.\n",
    "- *Comparability:* Standardizing transforms coefficients into directly comparable \"feature importances\".\n",
    "\n",
    "**Leakage Guard:** Standard scaling calculates `mean` and `std`. These must be `fitted` on `X_train` alone.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b904601f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "num_pipe = Pipeline([\n",
    "    ('imputer', num_imputer),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "# Assemble Preprocessor\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('num', num_pipe, num_cols),\n",
    "    ('cat', cat_pipe, cat_cols)\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbb98fdc",
   "metadata": {},
   "source": [
    "\n",
    "## 9. Feature Selection\n",
    "\n",
    "*Lecture material: Lecture 5 (Feature Selection), Lecture 6 (Linear Models), Lecture 9 (Pipeline Discipline).*\n",
    "\n",
    "**Conceptual Removal:** We explicitly deleted `duration` earlier due to target leakage.\n",
    "**Statistical Filters:** We can theoretically fit a `VarianceThreshold` or correlation filter here. Due to our rigorous pipeline assembly, any selection must be executed logically inside the pipeline using the Train set constraints.\n",
    "\n",
    "Since the feature space is quite small (`bank-additional` has ~20 raw features), deleting high-variance features manually isn't strictly necessary for a regularized linear model, as L2 regularization inherently pushes the coefficients of redundant/multicollinear features towards zero to maintain stability.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b90ae9b8",
   "metadata": {},
   "source": [
    "\n",
    "## 10. Addressing Class Imbalance\n",
    "\n",
    "*Lecture material: Lecture 3 (Class Imbalance), Lecture 4 (Evaluation Metrics).*\n",
    "\n",
    "**Assessment:** The majority class is `no` (~89%). This extreme skew is a severe concern because a naive model could default to simply guessing \"no\" to achieve 89% accuracy, completely ignoring the minority class (\"yes\").\n",
    "\n",
    "**Strategy & Justification:**\n",
    "Because we are utilizing Logistic Regression, instead of synthesizing fake points via SMOTE (which risks geometric boundary distortion in high-dimensional one-hot setups), the mathematically elegant approach is to modify the algorithm's loss function via `class_weight='balanced'`. \n",
    "This dynamically weights the loss gradients. A false negative (missing a 'yes') is penalized 9x more heavily than a false positive.\n",
    "\n",
    "**Implication if done before splitting (Leakage):**\n",
    "If we ran an oversampler like SMOTE on the *entire* dataset before splitting, overlapping synthetic examples would bleed directly into the Validation and Test sets. Our evaluation metrics would evaluate the model on fabricated data that already contains the training set's patterns, causing massively inflated scores that collapse in reality.\n",
    "\n",
    "**Evaluation Metric Selection:**\n",
    "Because of the imbalance, raw `Accuracy` is misleading. We will focus our evaluation heavily on `Precision` and `Recall` of the positive class (\"yes\"), as these measure performance exclusively on the target demographic.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b05688ba",
   "metadata": {},
   "source": [
    "\n",
    "## 11. Training a Logistic Regression Model\n",
    "\n",
    "*Lecture material: Lecture 6 (Logistic Regression), Lecture 9–11 (Model Evaluation and Metrics).*\n",
    "\n",
    "We assemble the final `Pipeline`, assuring that `X_val` is never `fitted`, only `transformed` and `predicted`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6a017f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Build final model pipeline\n",
    "model = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('clf', LogisticRegression(class_weight='balanced', max_iter=2000, random_state=42))\n",
    "])\n",
    "\n",
    "# Train!\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate on Validation\n",
    "y_val_pred = model.predict(X_val)\n",
    "\n",
    "acc = accuracy_score(y_val, y_val_pred)\n",
    "prec = precision_score(y_val, y_val_pred, pos_label='yes')\n",
    "rec = recall_score(y_val, y_val_pred, pos_label='yes')\n",
    "\n",
    "print(f\"Validation Accuracy:  {acc:.4f}\")\n",
    "print(f\"Validation Precision: {prec:.4f}\")\n",
    "print(f\"Validation Recall:    {rec:.4f}\")\n",
    "\n",
    "# Zero Rule Baseline\n",
    "majority_class = y_train.mode()[0]\n",
    "y_base_pred = [majority_class] * len(y_val)\n",
    "acc_base = accuracy_score(y_val, y_base_pred)\n",
    "print(f\"\\nZero-Rule Baseline Accuracy: {acc_base:.4f}\")\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6, 6))\n",
    "disp = ConfusionMatrixDisplay.from_predictions(\n",
    "    y_val, y_val_pred, \n",
    "    labels=model.classes_,\n",
    "    cmap='Blues', \n",
    "    ax=ax\n",
    ")\n",
    "plt.title('Validation Confusion Matrix\\n(Realistic Pipeline)')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14d6439d",
   "metadata": {},
   "source": [
    "\n",
    "**Interpretation:**\n",
    "By heavily weighting the minority class `class_weight='balanced'`, our Overall Accuracy has dropped significantly below the Zero-Rule Baseline (which lazily predicts \"no\"). \n",
    "However, **this is intentional and correct**. \n",
    "Instead of missing every single prospective client, the model now demonstrates strong *Recall*, capturing a massive segment of true subscribers (\"yes\"). In a marketing context, calling a few false positives is drastically cheaper than missing out on willing subscribers, proving our pipeline and structural decisions succeed at capturing structural variance rather than lazily chasing accuracy!\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
